% Encoding: UTF-8

@book{noauthor_adafruits_nodate,
	title = {Adafruit's {Raspberry} {Pi} {Lesson} 4. {GPIO} {Setup}},
	url = {https://learn.adafruit.com/adafruits-raspberry-pi-lesson-4-gpio-setup/configuring-i2c},
	abstract = {In this tutorial, you are not actually building anything, but you will learn how to configure your Raspberry Pi and install useful libraries ready to start attaching some external electronics to it.},
	language = {en-US},
	urldate = {2021-06-19},
	annote = {Publication Title: Adafruit Learning System},
	file = {Snapshot:/home/rabikkk/Zotero/storage/BXAVGTQ9/configuring-i2c.html:text/html},
}

@Book{perip,
  author     = {{vsergeev}},
  title      = {python-periphery: {A} pure {Python} 2/3 library for peripheral {I}/{O} ({GPIO}, {LED}, {PWM}, {SPI}, {I2C}, {MMIO}, {Serial}) in {Linux}.},
  copyright  = {MIT License},
  file       = {Snapshot:/home/rabikkk/Zotero/storage/WC8HIZ8F/python-periphery.html:text/html},
  keywords   = {odroid, Software Development - Embedded Systems, Software Development - Libraries - Python Modules, System - Hardware, System - Hardware - Hardware Drivers, beaglebone, embedded, gpio, i2c, led, linux, mmio, pwm, raspberrypi, rpi, serial, spi, uart},
  shorttitle = {python-periphery},
  url        = {https://github.com/vsergeev/python-periphery},
  urldate    = {2021-06-19},
}

@book{noauthor_opencv_nodate,
	title = {{OpenCV}: {OpenCV}-{Python} {Tutorials}},
	url = {$https://docs.opencv.org/4.5.2/d6/d00/tutorial_py_root.html$},
	urldate = {2021-06-19},
	file = {OpenCV\: OpenCV-Python Tutorials:/home/rabikkk/Zotero/storage/XAB8AC28/tutorial_py_root.html:text/html},
}

@TechReport{datasheet,
  author      = {Lupp, Schnorr/M},
  institution = {Heimann},
  title       = {{HTPA32x32dR2L5}.0/0.{85F7}.{7eHiC} {Thermopile} {Array} {With} {Lens} {Optics} {Rev3}.0},
  year        = {2018},
  month       = mar,
}

@book{noauthor_multimodalhandgesture_dataset_nodate,
	title = {{MultiModalHandGesture}\_dataset},
	url = {$http://www.gti.ssr.upm.es/data/MultiModalHandGesture_dataset$},
	urldate = {2021-06-20},
	file = {MultiModalHandGesture_dataset:/home/rabikkk/Zotero/storage/3AAJPDWK/MultiModalHandGesture_dataset.html:text/html},
}

@Book{aug,
  author     = {Himblot, Thomas},
  title      = {Data augmentation : boost your image dataset with few lines of {Python}},
  year       = {2018},
  month      = mar,
  note       = {Publication Title: Medium},
  abstract   = {To perform well, an image classifier needs a lot of images to train on. Deep learning algorithms can fail to classify let’s say cats, only…},
  file       = {Snapshot:/home/rabikkk/Zotero/storage/55RE3T3K/data-augmentation-boost-your-image-dataset-with-few-lines-of-python-155c2dc1baec.html:text/html},
  language   = {en},
  shorttitle = {Data augmentation},
  url        = {https://medium.com/@thimblot/data-augmentation-boost-your-image-dataset-with-few-lines-of-python-155c2dc1baec},
  urldate    = {2021-06-20},
}

@Article{lenet,
  author  = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal = {Proceedings of the IEEE},
  title   = {Gradient-based learning applied to document recognition},
  year    = {1998},
  issn    = {00189219},
  month   = nov,
  number  = {11},
  pages   = {2278--2324},
  volume  = {86},
  doi     = {10.1109/5.726791},
  url     = {http://ieeexplore.ieee.org/document/726791/},
  urldate = {2021-06-21},
}

@article{v_deep_2020,
	title = {A {Deep} {Convolutional} {Neural} {Network} {Approach} for {Static} {Hand} {Gesture} {Recognition}},
	volume = {171},
	doi = {10.1016/j.procs.2020.04.255},
	journal = {Procedia Computer Science},
	author = {V, Adithya and R, Rajesh},
	year = {2020},
	note = {Publisher: Elsevier BV},
	pages = {2353--2361},
}

@article{li_hand_2017,
	title = {Hand gesture recognition based on convolution neural network},
	volume = {22},
	doi = {10.1007/s10586-017-1435-x},
	number = {S2},
	journal = {Cluster Computing},
	author = {Li, Gongfa and Tang, Heng and Sun, Ying and Kong, Jianyi and Jiang, Guozhang and Jiang, Du and Tao, Bo and Xu, Shuang and Liu, Honghai},
	month = dec,
	year = {2017},
	note = {Publisher: Springer Science and Business Media LLC},
	pages = {2719--2729},
}

@Article{lecun1,
  author  = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal = {Nature},
  title   = {Deep learning},
  year    = {2015},
  month   = may,
  note    = {Publisher: Springer Science and Business Media LLC},
  number  = {7553},
  pages   = {436--444},
  volume  = {521},
  doi     = {10.1038/nature14539},
}

@Article{phung,
  author   = {{Phung} and {Rhee}},
  journal  = {Applied Sciences},
  title    = {A {High}-{Accuracy} {Model} {Average} {Ensemble} of {Convolutional} {Neural} {Networks} for {Classification} of {Cloud} {Image} {Patches} on {Small} {Datasets}},
  year     = {2019},
  issn     = {2076-3417},
  month    = oct,
  number   = {21},
  pages    = {4500},
  volume   = {9},
  abstract = {Research on clouds has an enormous influence on sky sciences and related applications, and cloud classification plays an essential role in it. Much research has been conducted which includes both traditional machine learning approaches and deep learning approaches. Compared with traditional machine learning approaches, deep learning approaches achieved better results. However, most deep learning models need large data to train due to the large number of parameters. Therefore, they cannot get high accuracy in case of small datasets. In this paper, we propose a complete solution for high accuracy of classification of cloud image patches on small datasets. Firstly, we designed a suitable convolutional neural network (CNN) model for small datasets. Secondly, we applied regularization techniques to increase generalization and avoid overfitting of the model. Finally, we introduce a model average ensemble to reduce the variance of prediction and increase the classification accuracy. We experiment the proposed solution on the Singapore whole-sky imaging categories (SWIMCAT) dataset, which demonstrates perfect classification accuracy for most classes and confirms the robustness of the proposed model.},
  doi      = {10.3390/app9214500},
  file     = {Full Text:/home/rabikkk/Zotero/storage/7IIN8YGS/Phung and Rhee - 2019 - A High-Accuracy Model Average Ensemble of Convolut.pdf:application/pdf},
  language = {en},
  url      = {https://www.mdpi.com/2076-3417/9/21/4500},
  urldate  = {2021-06-23},
}

@article{fukushima_neocognitron_1982,
	title = {Neocognitron: {A} new algorithm for pattern recognition tolerant of deformations and shifts in position},
	volume = {15},
	issn = {00313203},
	shorttitle = {Neocognitron},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0031320382900243},
	doi = {10.1016/0031-3203(82)90024-3},
	language = {en},
	number = {6},
	urldate = {2021-06-23},
	journal = {Pattern Recognition},
	author = {Fukushima, Kunihiko and Miyake, Sei},
	month = jan,
	year = {1982},
	pages = {455--469},
}

@Article{kriz,
  author   = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  journal  = {Communications of the ACM},
  title    = {{ImageNet} classification with deep convolutional neural networks},
  year     = {2017},
  issn     = {0001-0782, 1557-7317},
  month    = may,
  number   = {6},
  pages    = {84--90},
  volume   = {60},
  abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
  doi      = {10.1145/3065386},
  file     = {Full Text:/home/rabikkk/Zotero/storage/ANZ6Q5XI/Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf:application/pdf},
  language = {en},
  url      = {https://dl.acm.org/doi/10.1145/3065386},
  urldate  = {2021-06-23},
}

@article{phung_deep_2018,
	title = {A {Deep} {Learning} {Approach} for {Classification} of {Cloud} {Image} {Patches} on {Small} {Datasets}},
	volume = {16},
	url = {https://doi.org/10.6109/JICCE.2018.16.3.173},
	doi = {10.6109/JICCE.2018.16.3.173},
	number = {3},
	urldate = {2021-06-23},
	journal = {Journal of Information and Communication Convergence Engineering},
	author = {Phung, Van Hiep and Rhee, Eun Joo},
	month = sep,
	year = {2018},
	pages = {173--178},
}

@Comment{jabref-meta: databaseType:bibtex;}
