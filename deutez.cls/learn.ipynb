{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Welcome to Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXhuuc9p8D11"
      },
      "source": [
        "## **Sensor Configuration**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duJ1ajXW8KQG"
      },
      "source": [
        "HTPA32x32d Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vjrMmNT81PS"
      },
      "source": [
        "from periphery import I2C\n",
        "import time\n",
        "import numpy as np\n",
        "import copy\n",
        "import struct\n",
        "\n",
        "class HTPA:\n",
        "\n",
        "\n",
        "\tdef __init__(self, address):\n",
        "\t\tself.address = address\n",
        "\t\tself.i2c = I2C(\"/dev/i2c-1\")\n",
        "\t\tprint(\"Grabbing EEPROM data\")\n",
        "\t\teeprom = self.get_eeprom()\n",
        "\t\tself.extract_eeprom_parameters(eeprom)\n",
        "\t\tself.eeprom = eeprom\n",
        "\t\twakeup_and_blind = self.generate_command(0x01, 0x01)  # wake up the device\n",
        "\t\t# set ADC resolution to 16 bits\n",
        "\t\tadc_res = self.generate_command(0x03, self.mbit_value)# set ADC resolution in eeprom\n",
        "\t\tpull_ups = self.generate_command(0x09, self.pu_value)#pu value in eeprom\n",
        "\n",
        "\t\tprint(\"Initializing capture settings\")\n",
        "\n",
        "\t\tself.send_command(wakeup_and_blind)\n",
        "\t\tself.send_command(adc_res)\n",
        "\t\tself.send_command(pull_ups)\n",
        "\n",
        "\t\tself.set_bias_current(self.bias_value)  # bias value on eeprom\n",
        "\t\tself.set_clock_speed(0x050)  # clk value on eeprom self.clk_value\n",
        "\t\tself.set_cm_current(self.bpa_value)  # BPA value in eeprom\n",
        "\n",
        "\t\t# initialize offset to zero\n",
        "\t\tself.offset = np.zeros((32, 32))\n",
        "\n",
        "\n",
        "\n",
        "\tdef get_eeprom(self, eeprom_address=0x50):#Talking EEPROM\n",
        "\t\tquery = [I2C.Message([0x00, 0x00]), I2C.Message(\n",
        "\t\t    [0x00]*8000, read=True)]  # 8 Kbit Data from EEPROM\n",
        "\t\tself.i2c.transfer(eeprom_address, query)\n",
        "\t\treturn np.array(query[1].data)\n",
        "\n",
        "\n",
        "\tdef extract_eeprom_parameters(self, eeprom):#EEPROM Data\n",
        "\t\tself.VddCompgrad = eeprom[0x0340:0x0540:2] + (eeprom[0x0341:0x0540:2] << 8)\n",
        "\t\tself.VddCompoff = eeprom[0x0540:0x0740:2] + (eeprom[0x0541:0x0740:2] << 8)\n",
        "\n",
        "\t\tThGrad = eeprom[0x0740:0x0F40:2] + (eeprom[0x0741:0x0F40:2] << 8)\n",
        "\t\tThGrad = [tg - 65536 if tg >= 32768 else tg for tg in ThGrad]\n",
        "\t\tThGrad = np.reshape(ThGrad, (32, 32))\n",
        "\t\tThGrad[16:, :] = np.flipud(ThGrad[16:, :])\n",
        "\t\tself.ThGrad = ThGrad\n",
        "\n",
        "\t\tThOffset = eeprom[0x0F40:0x1740:2] + (eeprom[0x0F41:0x1740:2] << 8)\n",
        "\t\tThOffset = np.reshape(ThOffset, (32, 32))\n",
        "\t\tThOffset[16:, :] = np.flipud(ThOffset[16:, :])\n",
        "\t\tself.ThOffset = ThOffset\n",
        "\n",
        "\t\tP = eeprom[0x1740::2] + (eeprom[0x1741::2] << 8)\n",
        "\t\tP = np.reshape(P, (32, 32))\n",
        "\t\tP[16:, :] = np.flipud(P[16:, :])\n",
        "\t\tself.P = P\n",
        "\n",
        "\t\tepsilon = float(eeprom[0x000D])\n",
        "\t\tGlobalGain = eeprom[0x0055] + (eeprom[0x0056] << 8)\n",
        "\t\tPmin = eeprom[0x0000:0x0004]\n",
        "\t\tPmax = eeprom[0x0004:0x0008]\n",
        "\t\tPmin = struct.unpack('f', reduce(\n",
        "\t\t    lambda a, b: a+b, [chr(p) for p in Pmin]))[0]\n",
        "\t\tPmax = struct.unpack('f', reduce(\n",
        "\t\t    lambda a, b: a+b, [chr(p) for p in Pmax]))[0]\n",
        "\t\tself.PixC = (P * (Pmax - Pmin) / 65535. + Pmin) * \\\n",
        "\t\t             (epsilon / 100) * float(GlobalGain) / 100\n",
        "\t\tself.gradScale = eeprom[0x0008]\n",
        "\t\tself.VddCalib1 = eeprom[0x0046] + (eeprom[0x0047] << 8)\n",
        "\t\tself.VddCalib = eeprom[0x0046] + (eeprom[0x0047] << 8)\n",
        "\t\tself.VddCalib2 = eeprom[0x0048] + (eeprom[0x0049] << 8)\n",
        "\t\tself.Vdd = 3000.0\n",
        "\t\tself.VddScaling = eeprom[0x004E]\n",
        "\t\tself.Vddoff = eeprom[0x004F]\n",
        "\n",
        "\t\tself.PtatCalib1 = eeprom[0x003C] + (eeprom[0x003D] << 8)\n",
        "\t\tself.PtatCalib2 = eeprom[0x003E] + (eeprom[0x003F] << 8)\n",
        "\t\tPTATgradient = eeprom[0x0034:0x0038]\n",
        "\t\tself.PTATgradient = struct.unpack('f', reduce(\n",
        "\t\t    lambda a, b: a+b, [chr(p) for p in PTATgradient]))[0]\n",
        "\t\tPTAToffset = eeprom[0x0038:0x003c]\n",
        "\t\tself.PTAToffset = struct.unpack('f', reduce(\n",
        "\t\t    lambda a, b: a+b, [chr(p) for p in PTAToffset]))[0]\n",
        "\t\tself.clk_value = eeprom[0x001C]\n",
        "\t\tself.bias_value = eeprom[0x001B]\n",
        "\t\tself.pu_value = eeprom[0x001E]\n",
        "\t\tself.mbit_value = eeprom[0x001A]\n",
        "\t\tself.bpa_value = eeprom[0x001D]\n",
        "\t\tself.subt = np.zeros((32, 32))\n",
        "\t\t\n",
        "\t\t\n",
        "\tdef set_clock_speed(self, clk):#set clock speed\n",
        "\t\tif clk > 63:  # Max 64 Hz\n",
        "\t\t\tclk = 63\n",
        "\t\tif clk < 0:\n",
        "\t\t\tclk = 0\n",
        "\t\tclk = int(clk)\n",
        "\t\tprint(clk)\n",
        "\t\t# The measure time depends on the clock frequency settings.(optimal value)\n",
        "\t\tclk_speed = self.generate_command(0x06, clk)\n",
        "\t\tself.send_command(clk_speed)  # send clock data\n",
        "\n",
        "\t# This setting is used to adjust the common mode voltage of the preamplifier.\n",
        "\n",
        "\t\n",
        "\tdef set_cm_current(self, cm):\n",
        "\t\tcm = int(cm)\n",
        "\t\tcm_top = self.generate_command(0x07, cm)\n",
        "\t\tcm_bottom = self.generate_command(0x08, cm)\n",
        "\n",
        "\t\tself.send_command(cm_top)\n",
        "\t\tself.send_command(cm_bottom)\n",
        "\n",
        "\n",
        "\tdef set_bias_current(self, bias):\n",
        "\t\tbias = int(bias)\n",
        "\t\t# This setting is used to adjust the bias current of the ADC. A faster clock frequency requires a higher bias current setting.\n",
        "\t\tbias_top = self.generate_command(0x04, bias)\n",
        "\t\t# This setting is used to adjust the bias current of the ADC. A faster clock frequency requires a higher bias current setting.\n",
        "\t\tbias_bottom = self.generate_command(0x05, bias)\n",
        "\t\tself.send_command(bias_top)  # send bias top data\n",
        "\t\tself.send_command(bias_bottom)  # send bias bottom data\n",
        "\n",
        "\n",
        "    def temperature_compensation(self, im, ptat):#Thermal Offset Calculate\n",
        "\t    comp = np.zeros((32,32))\n",
        "\t    Ta = np.mean(ptat) * self.PTATgradient + self.PTAToffset\n",
        "\t\t#     temperature compensated voltage\n",
        "\t    comp = ((self.ThGrad * Ta) / pow(2, self.gradScale)) + self.ThOffset\n",
        "\t    Vcomp = np.reshape(im,(32, 32)) - comp\n",
        "\t    return Vcomp\n",
        "\n",
        "\tdef offset_compensation(self, im):#general environment offset send offset data\n",
        "\t\treturn im-self.offset\n",
        "\t\t\n",
        "\tdef sensitivity_compensation(self, im):#object temperature \n",
        "\t\treturn (im*100000000)/self.PixC\n",
        "\n",
        "\tdef measure_observed_offset(self):#Measuring observed offsets\n",
        "\t\tmean_offset = np.zeros((32, 32))\n",
        "\t\tfor i in range(10):\n",
        "\t\t\tprint(\"    frame \" + str(i))\n",
        "\t\t\t(p, pt) = self.capture_image()\n",
        "\t\t\tim = self.temperature_compensation(p, pt)\n",
        "\t\t\tmean_offset += (im-10)/10.0\t\n",
        "\t\tself.offset = mean_offset\n",
        "\n",
        "\n",
        "\tdef Vdd_Comperasition(self,im,ptat):#Vdd Comperasition calculate\n",
        "\t\tVVddComp=[]\n",
        "\t\tfor i in range(16):\n",
        "\t\t\tfor j in range(32):\n",
        "\t\t\t\tVVddComp.append((((self.VddCompgrad[(j+i*32)%128]*np.mean(ptat))/pow(2, self.VddScaling)+self.VddCompoff[(j+i*32)%128])/pow(2, self.Vddoff))*(self.Vdd-self.VddCalib1-((self.VddCalib2-self.VddCalib1)/(self.PtatCalib2-self.PtatCalib1))*(np.mean(ptat)-self.PtatCalib1)))\n",
        "\t\tfor i in range(16,32):\n",
        "\t\t\tfor j in range(32):\n",
        "\t\t\t\tVVddComp.append((((self.VddCompgrad[(j+i*32)%128+128]*np.mean(ptat))/pow(2, self.VddScaling)+self.VddCompoff[(j+i*32)%128+128])/pow(2, self.Vddoff))*(self.Vdd-self.VddCalib1-((self.VddCalib2-self.VddCalib1)/(self.PtatCalib2-self.PtatCalib1))*(np.mean(ptat)-self.PtatCalib1)))\n",
        "\t\tself.VVddComp=VVddComp\n",
        "\t\treturn im-np.reshape(self.VVddComp,(32, 32))\n",
        "\n",
        "\tdef measure_electrical_offset(self, blind=True):#measure_electrical_offset\n",
        "\t\tpixel_values = np.zeros(256)\n",
        "\t\tptats = np.zeros(8)\n",
        "        \n",
        "        self.send_command(self.generate_expose_block_command(0, blind=blind), wait=False)\n",
        "\n",
        "\t\tquery = [I2C.Message([0x02]), I2C.Message([0x00], read=True)]\n",
        "\n",
        "\t\tread_block = [I2C.Message([0x0A]), I2C.Message([0x00]*258, read=True)]\n",
        "\t\tself.i2c.transfer(self.address, read_block)\n",
        "\t\ttop_data = np.array(copy.copy(read_block[1].data))\n",
        "\n",
        "\t\tread_block = [I2C.Message([0x0B]), I2C.Message([0x00]*258, read=True)]\n",
        "\t\tself.i2c.transfer(self.address, read_block)\n",
        "\t\tbottom_data = np.array(copy.copy(read_block[1].data))\n",
        "\n",
        "\t\ttop_data = top_data[1::2] + (top_data[0::2] << 8)\n",
        "\t\tbottom_data = bottom_data[1::2] + (bottom_data[0::2] << 8)\n",
        "        # bottom data is in a weird shape\n",
        "\t\tpixel_values[0:128] = top_data[1:]\n",
        "\t\t# bottom data is in a weird shape\n",
        "\t\tpixel_values[224:256] = bottom_data[1:33]\n",
        "\t\tpixel_values[192:224] = bottom_data[33:65]\n",
        "\t\tpixel_values[160:192] = bottom_data[65:97]\n",
        "\t\tpixel_values[128:160] = bottom_data[97:]\n",
        "\t\tptats[block] = top_data[0]\n",
        "\t\tptats[7-block] = bottom_data[0]\n",
        "\n",
        "        self.elloff=pixel_values;\n",
        "\n",
        "\n",
        "\tdef electrical_offset(self,im):#electrical offset calculate\n",
        "        V_new = np.zeros((32,32))\n",
        "\t    for i in range(16):\n",
        "\t        for j in range(32):\n",
        "                V_new[i,j]=self.elloff[(j+i*32)%128]\n",
        "\t    for i in range(16,32):\n",
        "\t        for j in range(32):\n",
        "                V_new[i,j]=self.elloff[(j+i*32)%128+128]\n",
        "        self.V_new=V_new\n",
        "\t\treturn im - self.V_new\n",
        "\tdef capture_image(self, blind=False):\n",
        "\t\tpixel_values = np.zeros(1024)\n",
        "\t\tptats = np.zeros(8)\n",
        "\n",
        "\t\tfor block in range(4):\n",
        "\t\t\tprint(\"Exposing block \" + str(block))\n",
        "\t\t\tself.send_command(self.generate_expose_block_command(block, blind=blind), wait=False)\n",
        "\n",
        "\t\t\tquery = [I2C.Message([0x02]), I2C.Message([0x00], read=True)]\n",
        "\t\t\texpected = 1 + (block << 4)\n",
        "\n",
        "\t\t\tdone = False\n",
        "\n",
        "\t\t\twhile not done:\n",
        "\t\t\t\tself.i2c.transfer(self.address, query)\n",
        "\n",
        "\t\t\t\tif not (query[1].data[0] == expected):\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tdone = True\n",
        "\n",
        "\t\t\tread_block = [I2C.Message([0x0A]), I2C.Message([0x00]*258, read=True)]\n",
        "\t\t\tself.i2c.transfer(self.address, read_block)\n",
        "\t\t\ttop_data = np.array(copy.copy(read_block[1].data))\n",
        "\n",
        "\t\t\tread_block = [I2C.Message([0x0B]), I2C.Message([0x00]*258, read=True)]\n",
        "\t\t\tself.i2c.transfer(self.address, read_block)\n",
        "\t\t\tbottom_data = np.array(copy.copy(read_block[1].data))\n",
        "\n",
        "\t\t\ttop_data = top_data[1::2] + (top_data[0::2] << 8)\n",
        "\t\t\tbottom_data = bottom_data[1::2] + (bottom_data[0::2] << 8)\n",
        "\n",
        "\t\t\tpixel_values[(0+block*128):(128+block*128)] = top_data[1:]\n",
        "\t\t\t# bottom data is in a weird shape\n",
        "\t\t\tpixel_values[(992-block*128):(1024-block*128)] = bottom_data[1:33]\n",
        "\t\t\tpixel_values[(960-block*128):(992-block*128)] = bottom_data[33:65]\n",
        "\t\t\tpixel_values[(928-block*128):(960-block*128)] = bottom_data[65:97]\n",
        "\t\t\tpixel_values[(896-block*128):(928-block*128)] = bottom_data[97:]\n",
        "\n",
        "\t\t\tptats[block] = top_data[0]\n",
        "\t\t\tptats[7-block] = bottom_data[0]\n",
        "\n",
        "\t\tpixel_values = np.reshape(pixel_values, (32, 32))\n",
        "\n",
        "\t\treturn (pixel_values, ptats)\n",
        "\n",
        "\n",
        "\tdef generate_command(self, register, value):#periphery library register activate\n",
        "\t\treturn [I2C.Message([register, value])]\n",
        "\n",
        "\n",
        "\tdef generate_expose_block_command(self, block, blind=False):#read data command\n",
        "\t\tif blind:\n",
        "\t\t\treturn self.generate_command(0x01, 0x0B)\n",
        "\t\telse:\n",
        "\t\t\treturn self.generate_command(0x01, 0x09 + (block << 4))\n",
        "\n",
        "\n",
        "\tdef send_command(self, cmd, wait=True):#send data to registers\n",
        "\t\tself.i2c.transfer(self.address, cmd)\n",
        "\t\tif wait:\n",
        "\t\t\ttime.sleep(0.005) # sleep for 5 ms\n",
        "\n",
        "\n",
        "\tdef close(self):#closed device\n",
        "\t\tsleep = self.generate_command(0x01, 0x00)\n",
        "\t\tself.send_command(sleep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9aSnQ3Y8QQT"
      },
      "source": [
        "Capture Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5qZCTYc860D"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from htpa import *\n",
        "import pickle\n",
        "i = 0\n",
        "k = 0\n",
        "dev = HTPA(0x1A)\n",
        "\n",
        "while(True):\n",
        "    if (i == 5):\n",
        "    dev.measure_observed_offset()\n",
        "    dev.measure_electrical_offset()\n",
        "\n",
        "    pixel_values, ptats) = dev.capture_image()  # Capture Image\n",
        "    im = dev.temperature_compensation(pixel_values, ptats)  # thermal offset\n",
        "    im = dev.offset_compensation(im)  # general offset\n",
        "    if(k>5):\n",
        "    im=dev.electrical_offset(im)#electrical offset\n",
        "    im=dev.Vdd_Comperasition()#Vdd Comperasition\n",
        "    im = dev.sensitivity_compensation(im)#Sensitivity\n",
        "\n",
        "    # resize and scale image to make it more viewable on raspberry pi screen\n",
        "    im = cv2.resize(im, None, fx=12, fy=12)\t\n",
        "    im -= np.min(im)\n",
        "    im /= np.max(im)\n",
        "    imcolor=cv2.applyColorMap(im,cv2.COLORMAP_JET)\n",
        "\n",
        "    cv2.imshow('frame', im)\n",
        "    cv2.imshow('frame1', imcolor)\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "dev.close()\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3rltZTP8TAO"
      },
      "source": [
        "# **Creating Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbU8R1CA8bl7"
      },
      "source": [
        "Resize Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qIsrRWG8nhU"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "  \n",
        "src='/open_train/five/'\n",
        "filenames_train=os.listdir(src)\n",
        "\n",
        "print(len(filenames_train))\n",
        "for f_name in filenames_train:\n",
        "    im=Image.open(src+f_name)\n",
        "    # Size of the image in pixels (size of orginal image)\n",
        "    # (This is not mandatory)\n",
        "#    width, height = im.size\n",
        "  \n",
        "    # Setting the points for cropped image\n",
        "    # Setting the points for cropped image\n",
        "    left = 120\n",
        "    top = 45\n",
        "    right = 390\n",
        "    bottom = 240\n",
        "  \n",
        "    # Cropped image of above dimension\n",
        "    # (It will not change orginal image)\n",
        "    #im1 = im.crop((left, top, right, bottom))\n",
        "    im1=im1.resize((32, 32))\n",
        "    im1.save('/open_train/five_new/'+f_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oQl4VsW8gJz"
      },
      "source": [
        "Dataset Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zEWEH7j9AwU"
      },
      "source": [
        "# example of images augmentation\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "import os\n",
        "# Passing the path of the image directory\n",
        "src='/home/rabikkk/Desktop/final_project/last_dataset/close/'\n",
        "path1='/home/rabikkk/Desktop/final_project/last_dataset/train/';\n",
        "filenames_train=os.listdir(src)\n",
        "\n",
        "print(len(filenames_train))\n",
        "for f_name in filenames_train:\n",
        "    # load the image\n",
        "    img = load_img(src+f_name)\n",
        "# convert to numpy array\n",
        "    data = img_to_array(img)\n",
        "# expand dimension to one sample\n",
        "    samples = expand_dims(data, 0)\n",
        "# create image data augmentation generator\n",
        "    datagen1 = ImageDataGenerator(zoom_range=[0.8,1])\n",
        "# create image data augmentation generator\n",
        "    datagen = ImageDataGenerator(brightness_range=[0.6,1.0])\n",
        "# create image data augmentation generator\n",
        "    datagen2 = ImageDataGenerator(horizontal_flip=True)\n",
        "# prepare iterator\n",
        "    it = datagen.flow(samples, batch_size=1)\n",
        "    it1 = datagen1.flow(samples, batch_size=1)\n",
        "    it2 = datagen2.flow(samples, batch_size=1)\n",
        "    it = datagen.flow(samples, batch_size=4, save_to_dir=path1, save_prefix='index_test03', save_format='png')\n",
        "    it1 = datagen1.flow(samples, batch_size=5, save_to_dir=path1, save_prefix='index_test4', save_format='png')\n",
        "    it2= datagen2.flow(samples, batch_size=4, save_to_dir=path1, save_prefix='index_test5', save_format='png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ane__AG8jGu"
      },
      "source": [
        "# **Static Gesture Learning Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYkOvDCj8Dlo"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "#from keras.utils import to_categorical\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image,ImageOps\n",
        "from numpy import asarray  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4s-Awfj9G-y"
      },
      "source": [
        "Adding Train_set and Test_set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEHtdnqu8luT"
      },
      "source": [
        "#Training Set\n",
        "src='/home/rabikkk/Desktop/final_project/last_dataset/train/'\n",
        "filenames_train=os.listdir(src)\n",
        "\n",
        "categories_train=[]\n",
        "image_train=[]\n",
        "print(len(filenames_train))\n",
        "close=0\n",
        "index=0\n",
        "last=0\n",
        "open1=0\n",
        "for f_name in filenames_train:\n",
        "    image=Image.open(src+f_name).convert('RGB')\n",
        "    image=ImageOps.grayscale(image)\n",
        "    #image=cv2.imread(src+f_name)\n",
        "    #image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    numpydata = asarray(image)\n",
        "    image_train.append(numpydata)\n",
        "    #print(len(image_train))\n",
        "    category=f_name.split('_')[0]\n",
        "    if category=='close':\n",
        "        categories_train.append(0)\n",
        "        close+=1    \n",
        "    elif category=='index': \n",
        "        categories_train.append(1)\n",
        "        index+=1 \n",
        "    elif category=='last': \n",
        "        categories_train.append(2)\n",
        "        last+=1\n",
        "    else:\n",
        "        categories_train.append(3)\n",
        "        open1+=1\n",
        "\n",
        "df=pd.DataFrame({\n",
        "    'filename':filenames_train,\n",
        "    'category':categories_train\n",
        "})\n",
        "\n",
        "image_train=np.asarray(image_train)\n",
        "image_train = image_train.reshape((image_train.shape[0],32, 32,1))\n",
        "image_train = image_train.astype(\"float32\") / 255.0\n",
        "categories_train=np.asarray(categories_train)\n",
        "categories_train=categories_train.reshape(len(filenames_train),1)\n",
        "\n",
        "print(image_train.shape)\n",
        "print(categories_train.shape)\n",
        "print(close)\n",
        "print(last)\n",
        "print(open1)\n",
        "print(index)\n",
        "#print(categories_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOk6vSYN8EMY"
      },
      "source": [
        "#Test Set\n",
        "src='/home/rabikkk/Desktop/final_project/last_dataset/test/'\n",
        "filenames_test=os.listdir(src)\n",
        "\n",
        "categories_test=[]\n",
        "image_test=[]\n",
        "close=0\n",
        "index=0\n",
        "last=0\n",
        "open1=0\n",
        "print(len(filenames_test))\n",
        "for f_name in filenames_test:\n",
        "    image=Image.open(src+f_name).convert('RGB')\n",
        "    image=ImageOps.grayscale(image)\n",
        "     #image=cv2.imread(src+f_name)\n",
        "   #image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    numpydata = asarray(image)\n",
        "    image_test.append(numpydata)\n",
        "   # print(len(image_test))\n",
        "    category=f_name.split('_')[0]\n",
        "    if category=='close':\n",
        "        categories_test.append(0)\n",
        "        close+=1  \n",
        "    elif category=='index': \n",
        "        categories_test.append(1)\n",
        "        index+=1 \n",
        "    elif category=='last': \n",
        "        categories_test.append(2)\n",
        "        last+=1\n",
        "    else:\n",
        "        categories_test.append(3)\n",
        "        open1+=1\n",
        "\n",
        "\n",
        "df=pd.DataFrame({\n",
        "    'filename':filenames_test,\n",
        "    'category':categories_test\n",
        "})\n",
        "image_test=np.asarray(image_test)\n",
        "image_test = image_test.reshape((image_test.shape[0], 32, 32,1))\n",
        "image_test = image_test.astype(\"float32\") / 255.0\n",
        "#image_test =image_test.reshape(len(image_test),(32,32))\n",
        "#image_test= np.ndarray(shape=(2050, 32, 32, 1))\n",
        "#image_test=image_test/255.0\n",
        "#image_test=image_test.reshape(2008,32,32)\n",
        "categories_test=np.asarray(categories_test)\n",
        "categories_test=categories_test.reshape(len(filenames_test),1)\n",
        "\n",
        "print(image_test.shape)\n",
        "print(categories_test.shape)\n",
        "print(close)\n",
        "print(last)\n",
        "print(open1)\n",
        "print(index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoSL3I8o9OBn"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5fQbTEV8bE9"
      },
      "source": [
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D,AveragePooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout,LeakyReLU\n",
        "from tensorflow.keras.utils import plot_model\n",
        "#Instantieate an empty model\n",
        "model = Sequential(name=\"Static_Gesture_Model\")\n",
        "\n",
        "#C1 Convolutional Layer\n",
        "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=(32, 32,1)))\n",
        "#S2 Pooling Layer\n",
        "model.add(MaxPooling2D(strides=2))\n",
        "#C3 Convolutional Layer\n",
        "model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
        "#S4 Pooling Layer\n",
        "model.add(MaxPooling2D(strides=2))\n",
        "#Flatten the CNN output so that we can connect it with fully connected layers\n",
        "model.add(Flatten())\n",
        "#Fully Connected Layer\n",
        "model.add(Dense(256, activation='tanh'))\n",
        "#Fully Connected Layer\n",
        "model.add(Dense(84, activation='tanh'))\n",
        "#Fully Connected Layer\n",
        "model.add(Dense(10, activation='tanh'))\n",
        "#Output Layer with Softmax Activation\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSZAztbc9SAw"
      },
      "source": [
        "Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyO0tOHB7GAC"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "print(\"The length of list is: \", len(image_train))\n",
        "print(\"The length of list is: \", len(image_test))\n",
        "\n",
        "# early stopping\n",
        "early_stop = EarlyStopping(patience=30, monitor='val_loss')\n",
        "opt = keras.optimizers.Adam(learning_rate=0.000025)\n",
        "model.compile(optimizer=opt, #'adam'\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_name = \"model\"\n",
        "filepath='/home/rabikkk/Desktop/final_project/learning/' + model_name + '.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "logpath = '/home/rabikkk/Desktop/final_project/learning' + model_name + '.log'\n",
        "csv_logger = keras.callbacks.CSVLogger(logpath)\n",
        "callbacks_list = [checkpoint,csv_logger]\n",
        "history = model.fit(image_train, categories_train, epochs=100,validation_data=(image_test, categories_test), callbacks=[callbacks_list,early_stop])#callbacks=[callbacks_list,early_stop]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9VHmV7S9Yd0"
      },
      "source": [
        "Model Learning Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3zRNuIe9WGJ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, label='Training acc')\n",
        "plt.plot(epochs, val_acc, label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.ylim(0.9,1)\n",
        "plt.show()\n",
        "\n",
        "test_loss, test_acc = model.evaluate(image_test, categories_test, verbose=2)\n",
        "print(test_loss)\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_StrCdsN9cn9"
      },
      "source": [
        "Model Learning Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hmdC0fN9XrE"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.plot(epochs, loss, label='Training loss')\n",
        "plt.plot(epochs, val_loss, label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.ylim(0,0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EyYzYXV9k-C"
      },
      "source": [
        "Testing Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeLRY67S9fpZ"
      },
      "source": [
        "from keras.models import load_model  \n",
        "categories_valtest=[]\n",
        "model = tf.keras.models.load_model('/home/rabikkk/Desktop/final_project/learning/deneme.hdf5')\n",
        "images = []\n",
        "# Test edeceğin datanı preprocess et trainingde verdiğin input haline getir.\n",
        "main_folder0 ='/home/rabikkk/Desktop/final_project/last_dataset/testing/Set1/'\n",
        "#main_folder1 ='/home/rabikkk/Desktop/final_project/last_dataset/testing/Set2/'\n",
        "#main_folder2 ='/home/rabikkk/Desktop/final_project/last_dataset/testing/Set3/'\n",
        "#main_folder3 ='/home/rabikkk/Desktop/final_project/last_dataset/testing/Set4/'\n",
        "#main_folder4 ='/home/rabikkk/Desktop/final_project/last_dataset/testing/Set5/'\n",
        "for f_name in sorted(os.listdir(main_folder0)):\n",
        "    #image = Image.open(main_folder + f_name)\n",
        "    image = Image.open(main_folder0 + f_name)\n",
        "    image=ImageOps.grayscale(image)\n",
        "    #image_array = asarray(image)\n",
        "    image_array=np.array(image)\n",
        "    images.append(image_array)\n",
        "    category=f_name.split('_')[0]\n",
        "    if category=='close':\n",
        "      categories_valtest.append(0)\n",
        "    elif category=='index': \n",
        "      categories_valtest.append(1)\n",
        "    elif category=='last': \n",
        "      categories_valtest.append(2)\n",
        "    else:\n",
        "      categories_valtest.append(3)\n",
        "\n",
        "df=pd.DataFrame({\n",
        "    'filename':images,\n",
        "    'category':categories_valtest\n",
        "})\n",
        "categories_valtest=np.asarray(categories_valtest)\n",
        "categories_valtest=categories_valtest.reshape(len(images),1)\n",
        "images=np.asarray(images)\n",
        "images = images.reshape((images.shape[0],32, 32,1))\n",
        "images = images.astype(\"float32\") / 255.0\n",
        "print(images.shape)\n",
        "yhat = model.predict([images])\n",
        "#print('Predicted: %.3f' % yhat[0])\n",
        "predictions = model.predict_classes(images)\n",
        "\n",
        "print(predictions)\n",
        "# summarize the first 5 cases\n",
        "count=0;\n",
        "for i in range(len(images)):\n",
        "    if predictions[i]==categories_valtest[i]:\n",
        "        count+=1\n",
        "    #print('%s%d=> %d (expected %d)' % (f_name,i,predictions[i], categories_valtest[i])) \n",
        "print('Result:%f' % ((count/len(categories_valtest))*100))   \n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}